shell.prefix("set -eo pipefail; ")
configfile: "config.yaml"


CONTROLS = ["control1", "control2"]
SAMPLES  = ["sample1", "sample2"]

CONTROL_BAM = expand("aln/{sample}.sorted.bam", sample=CONTROLS)
SAMPLE_BAM = expand("aln/{sample}.sorted.bam", sample=SAMPLES)
ALL_SAMPLES = CONTROLS + SAMPLES
ALL_FASTQ = expand("reads/{sample}.fastq", sample = ALL_SAMPLES)
ALL_BED = expand("bed_files/{sample}.bed.gz", sample = ALL_SAMPLES)
rule align_pe:
     input: "reads/{sample}.R1.fastq.gz", "reads/{sample}.R2.fastq.gz"
     output: "aln/{sample}.raw.sam.gz"
     threads: 10
     message: "aligning"
     conda: "/data/zusers/andrewsg/env/chipseq.yml"
     shell: "bwa mem -M -k 32 -t {threads} /data/zusers/andrewsg/genome/hg19/hg19.fa {input} | gzip -c > {output} "

rule align_se:
     input: "reads/{sample}.fastq.gz"
     output: "aln/{sample}.raw.sam.gz"
     threads: 10
     message: "aligning"
     conda: "/data/zusers/andrewsg/env/chipseq.yml"
     shell: "bwa mem -M -k 32 -t {threads} /data/zusers/andrewsg/genome/hg19/hg19.fa {input} | gzip -c > {output} "
     
     
rule remove_badcigar_step1:
	input: "mapped_reads/{sample}.raw.sam.gz"
	output: "mapped_reads/{sample}.badcigar"
	threads:1
	message: "Removing reads with bad CIGAR"
	log: "logs/1_filtering/{sample}_filter"
	shell:
		"""
		zcat {input} | \
                awk 'BEGIN{{FS="\t"; OFS="\t"}}
                !/^@/ && $6!="*" {{
                cigar=$6; gsub("[0-9]+D","",cigar);
                n=split(cigar, vals, "[A-Z]");
                s=0; for(i=1;i<=n;i++) s=s+vals[i];
		seqlen=length($10);
		if(s!=seqlen) print $1"\t";}}' | sort | uniq > {output}
		"""

rule remove_badcigar_step2:
	input:
		sam = "mapped_reads/{sample}.raw.sam.gz",
		cigar = "mapped_reads/{sample}.badcigar"
	output: "mapped_reads/{sample}.raw.bam"
	conda: "/data/zusers/andrewsg/env/chipseq.yml"
	threads: 4
	params:
		prefix="{sample}"
	shell:
		"""
		zcat {input.sam} | grep -vF -f {input.cigar} | samtools view -@ {threads} -Su - | samtools sort -@ {threads} -T {params.prefix} -o {output} 
	        """


rule mark_duplicates:
	input: "mapped_reads/{sample}.raw.bam"
	output: 
		dup = "mapped_reads/{sample}.dup.bam",
		qc = "qc/{sample}.pcrDups.QC.txt"
	threads: 4
	message: "Marking PCR duplicates"
	log: "logs/1_filtering/{sample}_filter"
	shell:
			"""
			java -Xmx4G -jar picard-tools-1.141/picard.jar MarkDuplicates\
			INPUT={input} OUTPUT={output.dup} \
			METRICS_FILE={output.qc} ASSUME_SORTED=true \
			VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=false
			 
			"""

rule samtools_flag_filtering:
	input: "mapped_reads/{sample}.dup.bam"
	output:
		final_bam = "mapped_reads/{sample}.final.bam",
		final_bai = "mapped_reads/{sample}.final.bai"
	conda: "/data/zusers/andrewsg/env/chipseq.yml"
	threads: 10
	message: "Filtering out bad samtools flags"
	log: "logs/1_filtering/{sample}_filter"
	params:
		prefix="{sample}_finaltmp"
	shell:
                """
                samtools view -@ {threads} -F1804 -f2 -q 30 -u {input} | samtools sort -@ {threads} -T {params.prefix} -o {output.final_bam} - 
		samtools index {output.final_bam} {output.final_bai}

		""" 


rule generate_bedpe:
	input: 
		final_bam = "mapped_reads/{sample}.final.bam",
	output: 
		tmp_sort = temp("mapped_reads/{sample}.sort_name.bam"),
		bedpe = "bed_files/{sample}.bedpe.gz"
	conda: "/data/zusers/andrewsg/env/chipseq.yml"
	threads: 10
	params:
		prefix="{sample}_bedpe"
	message: "Creating bedpe"
	log: "logs/1_filtering/{sample}_filter"
	shell:
		"""
		samtools sort -@ {threads} -T {params.prefix} -o {output.tmp_sort} -n {input.final_bam}
		bedtools bamtobed -bedpe -mate1 -i {output.tmp_sort} |\
                gzip -c > {output.bedpe} 
		"""

rule generate_bed:
	input: "bed_files/{sample}.bedpe.gz",
	output: 
		bed = "bed_files/{sample}.bed.gz"
	threads: 4
	message: "Create bed"
	log: "logs/1_filtering/{sample}_filter"
	shell:
		"""zcat {input} | \
                awk 'BEGIN{{OFS="\t"; FS="\t"}}
                {{ chrom=$1; beg=$2; end=$6;
                if($2>$5){{beg=$5}} if($3>$6){{end=$3}}
                print chrom,beg,end
                }}' - | {config[sort]} --parallel={threads} -S 2G -k1,1 -k2,2n | \
                gzip -c > {output.bed}"""


rule mapstats_final:
	input: 
		final = "mapped_reads/{sample}.final.bam"
	output:
		final_mapstats = "qc/{sample}.final.flagstat.QC.txt"
	message: "Quality control check: Generating mapstats"
	log: "logs/2_qc/{sample}.qc"
	shell:"samtools flagstat {input.final} > {output.final_mapstats}"

rule mapstats_raw:
	input: 
		raw = "mapped_reads/{sample}.raw.bam"
	output:
		raw_mapstats = "qc/{sample}.raw.flagstat.QC.txt"
	message: "Quality control check: Generating mapstats"
	log: "logs/2_qc/{sample}.qc"
	shell:"samtools flagstat {input.raw} > {output.raw_mapstats}"


rule library_complexity:
	input:
		flt = "mapped_reads/{sample}.dup.bam"
	output:
		lib_complexity = "qc/{sample}.libComplexity.QC.txt",
		tmp_sort_bam = temp("qc/{sample}.flt.tmp.sort.bam")
	threads: 4
	params:
		prefix="{sample}_libcom"
	message: "Quality control: Computing library complexity"
	log: "logs/2_qc/{sample}.qc"
	shell:
		"""
		samtools sort -n -@ {threads} -T {params.prefix} -o {output.tmp_sort_bam} {input.flt}
		echo 1 | \
                     awk '{{print "#Total\tDistinct\tOne\tTwo\tNRF\tPBC1\tPBC2"}}' \
                     > {output.lib_complexity}
		
		bedtools bamtobed -bedpe -i {output.tmp_sort_bam} | \
                     awk 'BEGIN{{OFS="\t"}}{{print $1,$2,$4,$6,$9,$10}}' | \
                     grep -v 'chrM' | sort | uniq -c | \
                     awk 'BEGIN{{mt=0;m0=0;m1=0;m2=0; OFS="\t"}}
                               ($1==1){{m1=m1+1}} ($1==2){{m2=m2+1}} {{m0=m0+1}} {{mt=mt+$1}}
                          END{{print mt,m0,m1,m2,m0/mt,m1/m0,m1/m2}}'\
                     >> {output.lib_complexity}
		"""

rule x_cor:
	input: 
		final = "mapped_reads/{sample}.final.bam"
	output:
		temp_tagAlign = temp("xcor/{sample}.SE.tagAlign"),
		tagAlign = "xcor/{sample}.SE.tagAlign.gz",
	threads: 4
	message: "Running xcor"
	log: "logs/3_xcor/{sample}.xcor"
	shell:
		"""
		bamToBed -i {input} | awk 'BEGIN{{OFS="\\t"}}{{$4="N";$5="1000";print $0}}' |\
		tee {output.temp_tagAlign} |\
		gzip -c > {output.tagAlign}
		"""
rule spp:
	input: 
		temp_tagAlign = "xcor/{sample}.SE.tagAlign"
	output:
		subsample = "xcor/{sample}.filt.nodup.sample.SE.tagAlign",
		cc_score = "xcor/{sample}.filt.nodup.sample.SE.tagAlign.cc.qc", 
		temp_cc_score = temp("xcor/{sample}.filt.nodup.sample.SE.tagAlign.cc.qc.tmp"),
		cc_plot = "xcor/{sample}.filt.nodup.sample.SE.tagAlign.cc.plot.pdf"
	threads: 4	
	message: "Running spp : grep -v \"chrM\" {input.temp_tagAlign} |shuf -n 15000000 |awk 'BEGIN{{OFS=\"\\t\"}}{{$4=\"N\";$5=\"1000\";print $0}}' > {output.subsample}"
	shell:
		"""
		grep -v 'chrM' {input.temp_tagAlign} |\
		shuf -n 15000000  |awk 'BEGIN{{OFS="\\t"}}{{$4="N";$5="1000";print $0}}'  > {output.subsample} 
		
		Rscript run_spp_nodups.R -c={output.subsample} -p={threads} -filtchr=chrM -savp={output.cc_plot} -out={output.cc_score} > /dev/null 2>&1
        	sed -r  's/,[^\\t]+//g' {output.cc_score} > {output.temp_cc_score} 
		cp {output.temp_cc_score} {output.cc_score}		
		"""


rule pseudorepping:
	input:"bed_files/{sample}.bed.gz"
	output:
		shuf = temp("bed_files/shuf_{sample}"),
		psr1 = "bed_files/psr_{sample}.00.bed.gz",
		temp_psr1 = temp("bed_files/psr_{sample}.00.bed"),
		psr2 = "bed_files/psr_{sample}.01.bed.gz",
		temp_psr2 = temp("bed_files/psr_{sample}.01.bed")
	message:"Generating pseudoreps"
	log:"logs/4_pseudoreps"
	threads:4
	shell:
		"""
		#If the file is too big '--random-source' option will fail. That's why the '40000000'
		zcat {input} | shuf --random-source=<(zcat {input} | head -40000000) > {output.shuf}
		{config[split]} -d -nl/2 --additional-suffix=\".bed\" {output.shuf} bed_files/psr_{wildcards.sample}.
		
		{config[sort]} --parallel={threads} -S 2G \
                     -k1,1 -k2,2n {output.temp_psr1} | gzip -c > {output.psr1} 
		{config[sort]} --parallel={threads} -S 2G \
                     -k1,1 -k2,2n {output.temp_psr2} | gzip -c > {output.psr2} 
		"""


rule pooling_input:
	input: expand("bed_files/{sample}.bed.gz",sample = SAMPLES)
	output: "bed_files/pooled_inputs.bed.gz"
	message: "Pooling inputs together"
	log: "logs/4_pseudoreps"
	threads:4
	shell:
		"""
		zcat {input} | {config[sort]} --parallel={threads} -k1,1 -k2,2n | gzip -c > {output}
		"""

rule pseudorepping_pooled:
	input: 
		input1 = expand("bed_files/psr_{sample}.00.bed.gz",sample = SAMPLES),
		input2 = expand("bed_files/psr_{sample}.01.bed.gz",sample = SAMPLES)
	output: 
		rep1 = "bed_files/pooled_inputs.00.bed.gz",
		rep2 = "bed_files/pooled_inputs.01.bed.gz"
	message: "Pseudorepping pooled inputs together"
	log: "logs/4_pseudoreps"
	threads:4
	shell:
		"""
		zcat {input.input1} | {config[sort]} --parallel={threads} -k1,1 -k2,2n | gzip -c > {output.rep1}
		zcat {input.input2} | {config[sort]} --parallel={threads} -k1,1 -k2,2n | gzip -c > {output.rep2}
		"""

rule pooling_control:
	input: expand("bed_files/{sample}.bed.gz",sample = CONTROLS)
	output: "bed_files/pooled_controls.bed.gz"
	message: "Pooling controls together"
	log: "logs/4_pseudoreps"
	threads:4
	shell:
		"""
		zcat {input} | {config[sort]} --parallel={threads} -k1,1 -k2,2n | gzip -c > {output}
		"""


rule macs_callPeaks_inputs:
	input: 
		control = "bed_files/pooled_controls.bed.gz",
		trt = "bed_files/{sample}.bed.gz",
		cc_scores = "xcor/{sample}.filt.nodup.sample.SE.tagAlign.cc.qc"
	output:
		narrowPeak = "peaks/{sample}_peaks.narrowPeak",
	threads:1
	log: "logs/5_peakCalling"
	message: "Calling Peaks using MACS2"
	conda: "macs2.yaml"
	params:
		prefix="{sample}"
	run:
		import os, sys, time,subprocess
		#Calling narrowPeaks	
		shell("""
		fraglen=`cat {input.cc_scores}| cut -f3`
			
		macs2 callpeak \
                  -t {input.trt} -c {input.control}\
                  -f BEDPE -n peaks/{wildcards.sample}\
                  -g 2.7e9 -p 1e-2 --nomodel --shift 0 --extsize $fraglen \
                  --keep-dup all -B --SPMR
		cat {sample}_peaks.narrowPeak > {output}
		""")
		